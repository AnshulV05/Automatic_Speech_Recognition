{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UC3jKYBWSlo3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformers[torch] in /users/ug21/anshulv/.local/lib/python3.9/site-packages (4.37.2)\n",
            "Requirement already satisfied: requests in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: filelock in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from transformers[torch]) (1.26.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.11 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from transformers[torch]) (2.0.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from transformers[torch]) (0.28.0)\n",
            "Requirement already satisfied: psutil in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.8.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (11.7.99)\n",
            "Requirement already satisfied: jinja2 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (2.14.3)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (11.7.91)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (10.9.0.58)\n",
            "Requirement already satisfied: networkx in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (2.0.0)\n",
            "Requirement already satisfied: sympy in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (11.7.99)\n",
            "Requirement already satisfied: wheel in /opt/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.11->transformers[torch]) (0.37.1)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.11->transformers[torch]) (63.4.1)\n",
            "Requirement already satisfied: cmake in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from triton==2.0.0->torch!=1.12.0,>=1.11->transformers[torch]) (3.28.3)\n",
            "Requirement already satisfied: lit in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from triton==2.0.0->torch!=1.12.0,>=1.11->transformers[torch]) (17.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers[torch]) (2022.9.14)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers[torch]) (1.26.11)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from jinja2->torch!=1.12.0,>=1.11->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from sympy->torch!=1.12.0,>=1.11->transformers[torch]) (1.3.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: datasets in /users/ug21/anshulv/.local/lib/python3.9/site-packages (2.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (2023.10.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (1.26.1)\n",
            "Requirement already satisfied: filelock in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: xxhash in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: pandas in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (2.1.3)\n",
            "Requirement already satisfied: multiprocess in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: packaging in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (15.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from huggingface-hub>=0.19.4->datasets) (4.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.9.14)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: evaluate in /users/ug21/anshulv/.local/lib/python3.9/site-packages (0.4.1)\n",
            "Requirement already satisfied: packaging in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from evaluate) (23.2)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from evaluate) (2023.10.0)\n",
            "Requirement already satisfied: multiprocess in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: numpy>=1.17 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from evaluate) (1.26.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from evaluate) (2.18.0)\n",
            "Requirement already satisfied: responses<0.19 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: dill in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: pandas in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from evaluate) (2.1.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from evaluate) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: aiohttp in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2022.9.14)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.11)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from pandas->evaluate) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: jiwer in /users/ug21/anshulv/.local/lib/python3.9/site-packages (3.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from jiwer) (3.7.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: openai-whisper in /users/ug21/anshulv/.local/lib/python3.9/site-packages (20231117)\n",
            "Requirement already satisfied: numba in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from openai-whisper) (0.59.1)\n",
            "Requirement already satisfied: torch in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from openai-whisper) (2.0.1)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: tqdm in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from openai-whisper) (4.66.1)\n",
            "Requirement already satisfied: numpy in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from openai-whisper) (1.26.1)\n",
            "Requirement already satisfied: tiktoken in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from openai-whisper) (0.6.0)\n",
            "Collecting more-itertools\n",
            "  Downloading more_itertools-10.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lit in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from triton<3,>=2.0.0->openai-whisper) (17.0.6)\n",
            "Requirement already satisfied: cmake in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from triton<3,>=2.0.0->openai-whisper) (3.28.3)\n",
            "Requirement already satisfied: filelock in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from triton<3,>=2.0.0->openai-whisper) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from numba->openai-whisper) (0.42.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from tiktoken->openai-whisper) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from tiktoken->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (11.7.99)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (11.7.91)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (11.7.4.91)\n",
            "Requirement already satisfied: networkx in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (3.2)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (8.5.0.96)\n",
            "Requirement already satisfied: typing-extensions in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (4.8.0)\n",
            "Requirement already satisfied: jinja2 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (11.4.0.1)\n",
            "Requirement already satisfied: sympy in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from torch->openai-whisper) (11.10.3.66)\n",
            "Requirement already satisfied: wheel in /opt/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper) (0.37.1)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper) (63.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2022.9.14)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.11)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /users/ug21/anshulv/.local/lib/python3.9/site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Installing collected packages: more-itertools\n",
            "Successfully installed more-itertools-10.2.0\n"
          ]
        }
      ],
      "source": [
        "# Necessary installations\n",
        "!pip install transformers[torch]\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install jiwer\n",
        "!pip install -U openai-whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6kRFVMBVanm"
      },
      "source": [
        "## Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "CUDA_VISIBLE_DEVICES=0,1,2,3,4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZusSsfT_bhpU"
      },
      "outputs": [],
      "source": [
        "# Download dataset and unzip\n",
        "# !wget https://www.cse.iitb.ac.in/~pjyothi/cs753/dataset.zip\n",
        "# !unzip dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BQCtjZglSj33"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor, WhisperConfig, WhisperForConditionalGeneration\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "import evaluate\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "import whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hmK8H8M9SvXc"
      },
      "outputs": [],
      "source": [
        "# Load json files for each training split\n",
        "data_files = {\n",
        "    \"train\": \"dataset/CodeSwitched_Data/train.json\",\n",
        "    \"validation\": \"dataset/CodeSwitched_Data/valid.json\",\n",
        "    \"test\": \"dataset/CodeSwitched_Data/test.json\"\n",
        "}\n",
        "dataset = load_dataset(\"json\", data_files=data_files)\n",
        "\n",
        "# Update the audio paths to include appropriate folder name\n",
        "def prepend_folder_name(row):\n",
        "    row[\"audio\"] = 'dataset/CodeSwitched_Data/' + row[\"audio\"]\n",
        "    return row\n",
        "for key in dataset:\n",
        "    dataset[key] = dataset[key].map(prepend_folder_name)\n",
        "\n",
        "# Cast columns to appropriate features\n",
        "features = datasets.Features(\n",
        "    {\n",
        "        \"id\": datasets.Value(\"string\"),\n",
        "        \"transcription\": datasets.Value(\"string\"),\n",
        "        \"audio\": datasets.Audio(sampling_rate=16000),\n",
        "    }\n",
        ")\n",
        "dataset = dataset.map(features.encode_example, features=features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4AMD0JzSSwq0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# Load necessary processors\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Hindi\", task=\"transcribe\")\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Hindi\", task=\"transcribe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_WusTeQqSzGs"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(batch):\n",
        "    # load and resample audio data from 48 to 16kHz\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # compute log-Mel input features from input audio array\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    # encode target text to label ids\n",
        "    batch[\"labels\"] = tokenizer(batch[\"transcription\"]).input_ids\n",
        "    return batch\n",
        "\n",
        "dataset = dataset.map(prepare_dataset, num_proc=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YhxQzCCvARB0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample example:cycle चला सकते हो आराम से पैदल घूम सकते हो\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Sample example:{dataset['validation'][10]['transcription']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ka-9_GYafO0k"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's appended later anyway\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NqIYHmNPfO7P"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYs5I9e9fq8k"
      },
      "source": [
        "## Finetuning whisper model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6uHwO6ocfPAw"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"wer\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # replace -100 with the pad_token_id\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"wer\": wer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2hfuwGUzbMHm"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ae6205a676b4a3da314ae0721e67cb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3025c53e5d7641f390c7a1d71fef589b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ef76aae8940497582f17eef381f3619",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of parameters: 240.58M\n",
            "Number of trainable parameters: 33.08M\n"
          ]
        }
      ],
      "source": [
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "model.generation_config.language = \"hi\"  # assign the language of choice\n",
        "print(f'Total number of parameters: {sum([p.numel() for p in model.parameters() if p.requires_grad])/1e6:.2f}M')\n",
        "\n",
        "# STEP 1: Freeze all parameters of whisper base model.\n",
        "for param in model.model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# STEP 2: Unfreeze last 2 layers of encoder with layer norm\n",
        "for layer in model.model.encoder.layers[-2:]:\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "for param in model.model.encoder.layer_norm.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# STEP 3: Unfreeze last 2 layers of decoder with layer norm\n",
        "for layer in model.model.decoder.layers[-2:]:\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "for param in model.model.decoder.layer_norm.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(f'Number of trainable parameters: {sum([p.numel() for p in model.parameters() if p.requires_grad])/1e6:.2f}M')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QuF3ZlES4zH",
        "outputId": "296b6640-b78c-4f22-d729-a4354d1aab95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/users/ug21/anshulv/.local/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"runs/whisper-small-hi\",\n",
        "    per_device_train_batch_size=32,\n",
        "    gradient_accumulation_steps=1,\n",
        "    learning_rate=3e-3,\n",
        "    warmup_steps=10,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=5,\n",
        "    num_train_epochs=30,\n",
        "    per_device_eval_batch_size=32,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    logging_steps=25,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"wer\",\n",
        "    greater_is_better=False,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=processor.feature_extractor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNXkvJm85uWm"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45id9MFZCwr7"
      },
      "outputs": [],
      "source": [
        "# Create the reverse mapping adapting it from the original `WHISPER_MAPPING` in\n",
        "# the `convert_openai_to_hf.py` script:\n",
        "REVERSE_WHISPER_MAPPING = {\n",
        "    \"layers\": \"blocks\",\n",
        "    \"fc1\": \"mlp.0\",\n",
        "    \"fc2\": \"mlp.2\",\n",
        "    \"final_layer_norm\": \"mlp_ln\",\n",
        "    \".self_attn.q_proj\": \".attn.query\",\n",
        "    \".self_attn.k_proj\": \".attn.key\",\n",
        "    \".self_attn.v_proj\": \".attn.value\",\n",
        "    \".self_attn_layer_norm\": \".attn_ln\",\n",
        "    \".self_attn.out_proj\": \".attn.out\",\n",
        "    \".encoder_attn.q_proj\": \".cross_attn.query\",\n",
        "    \".encoder_attn.k_proj\": \".cross_attn.key\",\n",
        "    \".encoder_attn.v_proj\": \".cross_attn.value\",\n",
        "    \".encoder_attn_layer_norm\": \".cross_attn_ln\",\n",
        "    \".encoder_attn.out_proj\": \".cross_attn.out\",\n",
        "    \"decoder.layer_norm.\": \"decoder.ln.\",\n",
        "    \"encoder.layer_norm.\": \"encoder.ln_post.\",\n",
        "    \"embed_tokens\": \"token_embedding\",\n",
        "    \"encoder.embed_positions.weight\": \"encoder.positional_embedding\",\n",
        "    \"decoder.embed_positions.weight\": \"decoder.positional_embedding\",\n",
        "}\n",
        "\n",
        "\n",
        "def reverse_rename_keys(s_dict: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Renames the keys back from Hugging Face to OpenAI Whisper format.\n",
        "    \"\"\"\n",
        "    keys = list(s_dict.keys())\n",
        "    for orig_key in keys:\n",
        "        new_key = orig_key\n",
        "        for key_r, value_r in REVERSE_WHISPER_MAPPING.items():\n",
        "            if key_r in orig_key:\n",
        "                new_key = new_key.replace(key_r, value_r)\n",
        "\n",
        "        s_dict[new_key] = s_dict.pop(orig_key)\n",
        "    return s_dict\n",
        "\n",
        "\n",
        "def make_emb_from_linear(linear: nn.Linear) -> nn.Embedding:\n",
        "    \"\"\"\n",
        "    Converts a linear layer's weights into an embedding layer.\n",
        "\n",
        "    The linear layer's `in_features` dimension corresponds to the vocabulary size and its `out_features` dimension\n",
        "    corresponds to the embedding size.\n",
        "    \"\"\"\n",
        "    vocab_size, emb_size = linear.weight.data.shape\n",
        "    emb_layer = nn.Embedding(vocab_size, emb_size, _weight=linear.weight.data)\n",
        "    return emb_layer\n",
        "\n",
        "\n",
        "def extract_dims_from_hf(config: WhisperConfig) -> dict:\n",
        "    \"\"\"\n",
        "    Extracts necessary dimensions from Hugging Face's WhisperConfig.\n",
        "\n",
        "    Extracts necessary dimensions and related configuration data from the Hugging Face model and then restructure it\n",
        "    for the OpenAI Whisper format.\n",
        "    \"\"\"\n",
        "    dims = {\n",
        "        \"n_vocab\": config.vocab_size,\n",
        "        \"n_mels\": config.num_mel_bins,\n",
        "        \"n_audio_state\": config.d_model,\n",
        "        \"n_text_ctx\": config.max_target_positions,\n",
        "        \"n_audio_layer\": config.encoder_layers,\n",
        "        \"n_audio_head\": config.encoder_attention_heads,\n",
        "        \"n_text_layer\": config.decoder_layers,\n",
        "        \"n_text_head\": config.decoder_attention_heads,\n",
        "        \"n_text_state\": config.d_model,\n",
        "        \"n_audio_ctx\": config.max_source_positions,\n",
        "    }\n",
        "    return dims\n",
        "\n",
        "\n",
        "def convert_tfms_to_openai_whisper(hf_model, whisper_dump_path):\n",
        "    \"\"\"\n",
        "    Converts a Whisper model from the Hugging Face to the OpenAI format.\n",
        "\n",
        "    Takes in a Hugging Face Whisper model, extracts its state_dict, renames keys as needed, and then saves\n",
        "    the model OpenAI's format.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the HF model's state_dict\n",
        "    state_dict = model.state_dict()\n",
        "\n",
        "    # Use a reverse mapping to rename state_dict keys\n",
        "    state_dict = reverse_rename_keys(state_dict)\n",
        "\n",
        "    # Extract configurations and other necessary metadata\n",
        "    dims = extract_dims_from_hf(model.config)\n",
        "\n",
        "    # Remove the proj_out weights from state dictionary\n",
        "    del state_dict[\"proj_out.weight\"]\n",
        "\n",
        "    # Construct the Whisper checkpoint structure\n",
        "    state_dict = {k.replace(\"model.\", \"\", 1): v for k, v in state_dict.items()}\n",
        "    whisper_checkpoint = {\"dims\": dims, \"model_state_dict\": state_dict}\n",
        "\n",
        "    # Save in Whisper's format\n",
        "    torch.save(whisper_checkpoint, whisper_dump_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKZ9D-5KDCDM"
      },
      "outputs": [],
      "source": [
        "model_save_file = \"whisper-small-finetuned.pt\"\n",
        "convert_tfms_to_openai_whisper(model, model_save_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
